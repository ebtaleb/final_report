\chapter{The OCaml native compiler\label{cha:chapter3}}

The OCaml language support multiple programming paradigms:
\begin{itemize}
    \item functional programming style, that consists mostly of pure computations that always
        evaluate to the same value across different executions for the same arguments
        and do not produce side effects.
    \item in contrast, in the imperative programming style,
        use of assignments to mutable variables can result in side effects
        where the return value of a routine may change across multiple executions,
        modify some state in the program or perform input/output operations
        such as writing to a file.
\end{itemize}

In both styles, stepping through function calls is fine, regardless of whether
they are pure or not.
However, in the case of side-effecting functions, one must be vary of the order of
evaluation of arguments, as they may affect the return value.

\vspace{5mm}

Moreover, it may not make much sense to source debug functional constructs
the same way one would with with equivalent imperative constructs.
The use of map and filter functions, first class functions and
partial function application come to mind.
Nonetheless, bugs bound to those constructs are usually programming
logic errors, not run-time or compiler errors.

\section{The native compilation process}

A OCaml source program goes through multiple transformations:

\begin{description}
    \item[lexing - lexical analysis]
        split the program from a sequence of characters into a sequence of
        tokens, contain file and line location information.

    \item[parsetree - syntactic analysis]
        check whether the program as a sequence of tokens is gramatically valid, and if so
        construct an abstract syntax tree.

    \item[typedtree - semantic analysis]
        perform type inference and checking, annotate AST with type information

    \item[lambda]
        AST with pattern matching translation,
        % to if and switch constructs,
        elimination of classes and modules,
        discards type information and most of location information,
        %maps the source code to runtime memory model,
        generates unique names for identifiers by appending a number stamp to them
        (variable shadowing)

    \item[clambda]
        closure conversion, inlining, constant propagation and folding

    \item[cmm]
        primitives conversion % high level to low lvl operations

    \item[mach]
        allocation merging, register liveness analysis, register spilling and allocation

    \item[linearize]
        the AST becomes a sequence of pseudo machine code instructions

    \item[emit] assembly code generation

    \item[assembling and linking final binary]
\end{description}

\begin{tikzpicture}[remember picture,overlay]
    \node[xshift=0cm,yshift=0cm] at (current page.center) {
            \input{./tikz_pic/compil.tikz}
        };
\end{tikzpicture}

\clearpage

\section{Additions to the compiler}

\subsection{Location information}

Let us define first what a debugging event is, quoting the OCaml manual:

\begin{quotation}
    Events are “interesting” locations in the source code, corresponding to the
    beginning or end of evaluation of “interesting” sub-expressions. Events are
    the unit of single-stepping (stepping goes to the next or previous event
    encountered in the program execution). Also, breakpoints can only be set at
    events. Thus, events play the role of line numbers in debuggers for
    conventional languages. \autocite{events}
\end{quotation}

Those events are inserted in OCaml bytecode programs for use with the source-level bytecode
debugger \textit{ocamldebug}. \\

Among the debugging information to be added, line information is important,
both for stepping into the source program statement by statement,
and also for setting breakpoints by file and line number.

The idea here is to propagate the location information contained in those events
through the native code backend, by wrapping all IR nodes into a record
containing the node and a field with location information from the debugging
event.

\begin{lstlisting}
type t = {
  dinfo_file: string;
  dinfo_line: int;
  dinfo_char_start: int;
  dinfo_char_end: int
}

type 'a expression = {
  exp: 'a;
  dbg: t;
}
\end{lstlisting}

This has been done for every native backend pass all the way up to the linearize
pass, whose the instruction record structure already contains such a field.

Then, location information was attached to some particular constructs:

\begin{itemize}
    \item integers - as the empty list [] and None from the option type are represented as integers
        this is useful in pattern matching as well
    \item primitives - in particular :

%- explain what a primitive is, what it is responsible for

%prim operations mirroring bytecode instructions maybe?
%may refer to external C function
%assignments, allocation, comparisons, string/float/integer/boolean operations,
%boxed/unboxed
        \begin{itemize}
            \item
                Test comparisons in if-then-else statements :
                since primitives have location information, it is possible to
                stop at the comparison test.
                Pattern matching can take advantage of this too, since they are compiled into
                if and switches constructs at the lambda pass.
            \item
                setfield primitive - responsible for mutable assignments of variables, mutable
                fields in records and non-constant let assignments
            \item
                allocation - before initializing any boxed values
        \end{itemize}
\end{itemize}

At the code generation step, the code emitter uses two notable debugging
assembly directives, specific to the GNU assembler as it is used in the
compilation process:

%https://sourceware.org/binutils/docs-2.26/as/Loc.html
%https://sourceware.org/binutils/docs-2.26/as/File.html

\begin{itemize}
    \item .file fileno filename : assigning a positive integer to a filename
    \item .loc fileno lineno [column] [options] : add a row to the .debug\_line
        line information matrix for the current compilation unit, map a source
        file and line number to the assembly instructions that follow
\end{itemize}

Avantages and disadvantages of this method are listed below:

\begin{itemize}
\fail
Heavy modifications on the backend are required, as the need for a debugging
field in intermediary languages was not anticipated by the core team. This
affects the Clambda, Cmm and Mach passes.
\fail This approach lacks accuracy, loss of information is still occuring as code
is being expanded and transformed. Propagation of information for specific constructs
must be done on a case-by-case basis.
%\item Valeurs disponibles pas toujours cohérentes
% csq du manque de precision
\tick Although a prior application of a code patch is necessary, further modifications
and propagation of information become easier, as opposed to add a location field
to every construct record definition in each IR.
\tick It allows stepping into imperative constructs such as branching and
assignments.
\end{itemize}

\subsection{Runtime location of variables}

Two additional passes were introduced into the backend, both using
forward data-flow analysis.

\clearpage
\subsubsection{available\_regs}

This pass takes a function expressed in Mach code as input, and
return Mach code with each instructions annotated
with a set of available variables for each instruction, that is variables whose
value can be accessed by a debugger at runtime.

Mach form is comparable to a \gls{cfg} and can be traversed as such.

The data-flow equations used for a given instruction are as follows:
\[
    \textit{out}_{i} = \bigcup_{s \in succ_{i}} \textit{in}_{i}
\]
\[
    \textit{in}_{i} = (\textit{out}_{i} - \textit{kill}_{i}) \cup \textit{gen}_{i}
\]

where \textit{in} is the set of symbolic registers used by a particular variable right before
current instruction gets executed,
\textit{kill} the set of overwritten register variables considered as unavailable
because of the destructive nature of the current instruction, like a function
call or spilling a register's content,
and \textit{gen} the set containing registers relevant to the
analysis for the current instruction, on the criteria of holding the value of an identifier.

A register can be considered as available at the start of an instruction
if it is available at the end of each of the instruction's predecessors.

%calling conventions differ from C
When about to call OCaml functions, arguments are passed in registers first
and the rest on the stack.
The OCaml runtime tries to reuse registers as much as it can, variables
are spilled on the stack if no registers are available.
Callee functions can clobber their callers' arguments.

\subsubsection{available\_ranges}

This pass operates over a function declaration in the Linearize language,
annotated with information collected beforehand by available\_regs.
It calculates for each variable/ identifier used in target function the memory
addresses subranges where its content can be inspected, and for each subrange, the
place where the content can be accessed (in registers or on the stack).

A sub-range contains a starting instruction, a starting label, a ending label
and a symbolic register.
A range is made of a list of sub-ranges, a lower bound label, an upper bound label
such as no overlaps between subranges
Finally, a ranges dictionary maps an identifier to a particular range.

Labels are then inserted in the linearized code to demarcate variable availability in the
function.

%\begin{algorithmic}[1]
    %\If{some condition is true}
    %\State do some processing
    %\ElsIf{some other condition is true}
    %\State do some different processing
    %\ElsIf{some even more bizarre condition is met}
    %\State do something else
    %\Else
    %\State do the default actions
    %\EndIf
%\end{algorithmic}

\begin{itemize}
    \item Unique identifiers generated because of variable shadowing, and identifiers not present in the source (for
        bookkeeping purposes such as bound checking) introduced at the lambda pass
        are taken into account in the data-flow analysis.
    \item Not every value binding is captured because of constant folding, where a static
        constant is calculated and loaded as a constant in a register instead, those
        avriable are thus not captured by the passes.
    \item As a consequence of the lack of precision from the debugging events propagation,
        location information directives are not put at the most suitable assembly instruction,
        and values might not be updated when they should at some point in the source.
\end{itemize}

\subsection{DWARF emitter}

\begin{itemize}
    \item Using the labels generated by available\_ranges, this module calculates offset differences
        betweens the label subranges to populate the .debug\_loc section responsible for
        tracking the runtime location of variables.
    \item It also populates the .debug\_info section as well, building and encoding
        debugging entries.
    \item Each variable DIE is separated by a lexical block with a specific address range.
    \item No type information is encoded in the DWARF data, as it will be handled later separately.
    \item DWARF information can be added to the binary using the `-gdwarf` compiler option flag.
\end{itemize}

The DWARF emitter and runtime location of variables features are both credited to
Mark Shinwell from Jane Street Europe.

Minor adjustments and bug fixes were made to both features to work properly with
the OCamlPro codebase.

\subsection{Type information export}

We can now determine where a particular variable value is located in memory, but
we do not know how to interpret it. Type information of variables is necessary
at this point, but by the time the compilation process reach its latter end,
type information is already discarded. \\

The OCaml compiler offers the option of exporting the \gls{ast} annotated with type
information at the typedtree pass into a file with the cmt extension (using the
flag -bin-annot). \\

A compiler flag allowing serialization and export it as a symbol
into the binary was adjoined, called `-dvb`.\\
It is easier to manipulate, but comes at the cost of a bigger binary
size.\\

That information will be used later to build a symbol table for use in the
ocp-lldb native debugger.

