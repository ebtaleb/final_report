\chapter{The OCaml native compiler\label{cha:chapter3}}

The OCaml language support multiple programming paradigms:
\begin{itemize}
    \item functional programming style, that consists mostly of pure computations that always
        evaluate to the same value across different executions for the same arguments
        and do not produce side effects.
    \item in contrast, in the imperative programming style,
        use of assignments to mutable variables can result in side effects
        where the return value of a routine may change across multiple executions,
        modify some state in the program or perform I/O operations
        such as writing to a file.
\end{itemize}

In both styles, stepping through function calls is fine, regardless of whether
they are pure or not.
However, in the case of side-effecting functions, one must be vary of the order of
evaluation of arguments, as they may affect the return value.

Moreover, it may not make much sense to source debug functional constructs
the same way one would with with equivalent imperative constructs.
The use of map and filter functions, first class functions and
partial function application come to mind.
Nonetheless, bugs bound to those constructs are usually programming
logic errors, not run-time or compiler errors.

\section{The native compilation process}

A OCaml source program goes through multiple passes/transformations:

\begin{description}
    \item[lexing - lexical analysis]
        split the program from a sequence of characters into a sequence of
        tokens, contain file and line location information.

    \item[parsetree - syntactic analysis]
        check whether the program as a sequence of tokens is gramatically valid, and if so
        construct an abstract syntax tree.

    \item[typedtree - semantic analysis]
        perform type inference and checking, annotate AST with type information

    \item[lambda]
        AST with pattern matching translation,
        % to if and switch constructs,
        elimination of classes and modules,
        discards type information and most of location information,
        %maps the source code to runtime memory model,
        generates unique names for identifiers by appending a number stamp to them
        (variable shadowing)

    \item[clambda]
        closure conversion (to lexical blocks?), inlining, constant propagation
        and folding

    \item[cmm]
        primitives conversion % high level to low lvl operations

    \item[mach]
        allocation merging, register liveness analysis, register spilling and allocation

    \item[linearize]
        the AST becomes a sequence of pseudo machine code instructions

    \item[emit] assembly code generation

    \item[assembling and linking final binary]
\end{description}

%\afterpage{%
\afterpage{\clearpage}
\begin{figure}
  \centering
\begin{tikzpicture}[node distance=3pt,outer sep=0pt,
blueb/.style={
  draw=white,
  fill=mybluei,
  rounded corners,
  text width=2.5cm,
  font={\scriptsize\sffamily\bfseries\color{white}},
  align=center,
  text height=12pt,
  text depth=9pt},
greenb/.style={blueb,fill=mygreen},
]
\node[blueb, fill=mygreen] (prog) {OCaml source file};
\node[left=of prog] (i) {Input};
\node[blueb, below=of prog] (lex) {Lexing};
\node[blueb, below=of lex] (par) {Parsing};
\node[blueb, below=of par] (typ) {Typing};
\node[blueb, below=of typ] (lam) {Lambda};
\node[blueb, below=of lam] (clam) {Clambda};
\node[blueb, below=of clam] (cmm) {Cmm};
\node[blueb, below=of cmm] (mac) {Mach};
\node[blueb, below=of mac] (lin) {Linearize};
\node[blueb,below=of lin] (cgen) {Emit};
\node[blueb,below=of cgen] (asm) {Assembling - Linking};
\node[blueb,fill=mypink,below=of asm] (bin) {OCaml binary};
\node[left=of bin] (o) {Output};

\path [line] (asm.south) -- node [above] {} (bin) ;
\end{tikzpicture}
\end{figure}

\afterpage{\clearpage}
%\clearpage
%}

\section{Additions to the compiler}

\subsection{Location information}

Let us define first what a debugging event is, quoting the OCaml manual:

\begin{quotation}
    Events are “interesting” locations in the source code, corresponding to the
    beginning or end of evaluation of “interesting” sub-expressions. Events are
    the unit of single-stepping (stepping goes to the next or previous event
    encountered in the program execution). Also, breakpoints can only be set at
    events. Thus, events play the role of line numbers in debuggers for
    conventional languages. \autocite{events}
\end{quotation}

Those events are inserted in OCaml bytecode programs for use with the source-level bytecode
debugger \textit{ocamldebug}. \\

Among the debugging information to be added, line information is important,
both for stepping into the source program statement by statement,
and also for setting breakpoints by file and line number.

The idea here is to propagate the location information contained in those events
through the native code backend, by wrapping all IR nodes into a record
containing the node and a field with location information from the debugging
event.

\begin{lstlisting}
type t = {
  dinfo_file: string;
  dinfo_line: int;
  dinfo_char_start: int;
  dinfo_char_end: int
}

type 'a expression = {
  exp: 'a;
  dbg: t;
}
\end{lstlisting}

This has been done for every native backend pass all the way up to the linearize
pass, whose instruction record that already contains such a field.

Then, location information was attached to some particular constructs:

\begin{itemize}
    \item integers - as empty list [] and None from the option type represented as integers
        useful in pattern matching as well
    \item primitives - in particular :

%- explain what a primitive is, what it is responsible for

%prim operations mirroring bytecode instructions maybe?
%may refer to external C function
%assignments, allocation, comparisons, string/float/integer/boolean operations,
%boxed/unboxed
        \begin{itemize}
            \item
                Test comparisons in if-then-else statements
                since primitives have location information, it is possible to
                stop at the comparison test.
                Pattern matching can take advantage of this too, since they are compiled into
                if and switches constructs at the lambda pass.
            \item
                setfield primitive - responsible for mutable assignments of variables, mutable
                fields in records and non-constant let assignments
            \item
                allocation - before initializing any boxed values
        \end{itemize}
\end{itemize}

At the code generation step, the code emitter uses two notable debugging
assembly directives, specific to the GNU assembler as it is used in the
compilation process:

%https://sourceware.org/binutils/docs-2.26/as/Loc.html
%https://sourceware.org/binutils/docs-2.26/as/File.html

\begin{itemize}
    \item .file fileno filename : assigning a positive integer to a filename
    \item .loc fileno lineno [column] [options] : add a row to the .debug\_line
        line information matrix for the current compilation unit, map a source
        file and line number to the assembly instructions that follow
\end{itemize}

Avantages and disadvantages:

\begin{itemize}
\fail
Heavy modifications on the backend
% huge patch when trying to add a debugging field to every IR node
% languages des passes backend natif n'a pas prevu pour l'adjonction d'info de debug
\fail lack of accuracy, loss of information still occuring as code is still expanded and transformed
%\item Valeurs disponibles pas toujours cohérentes
% csq du manque de precision
\tick Although the initial work require a bug code patch, further modifications
and information propagation becomes easier, as opposed to add a location field
to every construct record definition
\tick Can step more naturraly into imperative constructs
(pattern matching/branching, assignments)
\end{itemize}

\subsection{Runtime location of variables}
%calling conventions differ from C
When about to call OCaml functions, arguments are passed in registers first
and remainders on the stack.
The OCaml runtime tries to reuse registers as much as it can, variables
are spilled on the stack if no registers are available.
Callee functions can clobber their callers' arguments.

Add 2 passes into the backend: available\_regs and available\_ranges
using forward data-flow analysis operating on Mach IR, can be traversed like
a \gls{cfg}
intraprocedural DFA

available\_regs overview :
takes a function expressed in Mach code as input
return Mach code with each ins annotated with set of `registers` identifiers
augmented with a set of available variables for each instruction

whose value can be accessed (hence available) by a debugger at runtime

The data-flow equations used for a given instruction
\[
    \textit{out}_{b} = \bigcup_{s \in succ_{b}} \textit{in}_{s}
\]
\[
    \textit{in}_{b} = (\textit{out}_{b} - \textit{kill}_{b}) \cup \textit{gen}_{b}
\]
in : set of symbolic registers used by a particular variable right before
current instruction gets executed

kill : set of clobbered/overwritten reg variables considered as unavailable because of the nature of the
current instruction
%out(b) = 0
%for s in succ(b)
  %out(b) = out(b) or in(s)
  %in(b) = (out(b) and not kill(b)) or gen(b)
available\_ranges:
operates over Linearize function declaration annotated with available\_regs pass
calculates for each variable/ identifier used in target function the memory
addresses ranges where its content can be inspected, and for each range, the
place where the content can be accessed (in registers or on the stack)

available before

sub-range : starting instruction * starting label * ending label * symbolic
register
range : list of sub-ranges * minimal/lowest position/label * highest label
such as no overlaps between subranges

%new instruction_descr in linearize.ml

%- Lavailable_subranges of int option ref
%- Lprologue

ranges : map from identifiers to a range

process each identifer found in a Linearize function declaration

and insert labels to delimit/demarcate variable availability in the Linearize
fundecl, hence it modifies it

with information collected beforehand by available\_regs

\begin{algorithmic}[1]
    \If{some condition is true}
    \State do some processing
    \ElsIf{some other condition is true}
    \State do some different processing
    \ElsIf{some even more bizarre condition is met}
    \State do something else
    \Else
    \State do the default actions
    \EndIf
\end{algorithmic}


unique identifier with unique stamp is generated in cases variable shadowing overwrites former value

not every value binding is captured becaused of constant folding, static
constant stored and loaded in register instead

as a consequence of the lack of precision from the events,
location information directives are not put at the
most suitable assembly instruction, and values might not be updated when they should
at some point in the source and vice versa

\subsection{DWARF emitter}

using the labels generated by available\_ranges, calculates offset differences
betweens label subranges to populate the .debug\_loc section

populate the  .debug\_info as well with function/routine DIEs

no type information encoded in the DWARF, will be handled later separately.

output each variable DIE in its own, separate lexical block with specific range
no nesting of lexical block

DWARF information can be added to the binary using the `-gdwarf` compiler option flag.

The DWARF emitter and runtime location of variables features are both credited to
Mark Shinwell from Jane Street Europe.

Minor adjustments and bug fixes were made for both to work properly with the initial codebase.

\subsection{Type information}

We can now determine where a particular variable value is located in memory, but
we do not know how to interpret it. Type information of variables is necessary
at this point, but by the time the compilation process reach its latter end,
type information is already discarded. \\

The OCaml compiler offers the option of exporting the \gls{ast} annotated with type
information at the typedtree pass into a file with the cmt extension (using the
flag -bin-annot). \\

Typed \gls{ast} is serialized into the binary instead of a separate file.

It is more practical/easier to manipulate, but comes at the cost of a bigger binary
size.
It can be added to the binary using the `-dvb` compiler flag.\\

That information will be used later to build a symbol table for use in the
ocp-lldb native debugger.

