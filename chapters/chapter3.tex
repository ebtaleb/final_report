\chapter{The OCaml native compiler\label{cha:chapter3}}

The OCaml language support multiple programming paradigms:

functional programming style, that consists mostly of pure computations that always
evaluate to the same value across different executions for the same arguments
and do not produce side effects.

in contrast, in the imperative programming style
use of assignments to mutable variables can result in side effects
where the return value of a routine may change across multiple executions,
mutate/modifie some state in the program, perform I/O operations
such as reading from/writing to a file

In both styles, stepping through function calls is fine, regardless of whether
they are pure or not.
However, in the case of side-effect functions, one must be vary of the order of
evaluation of arguments, as they may affect the return value.

Moreover, constructs specific to functional programming style such as the map
and filter functions, the use of first class functions taking other functions as
arguments and partial function application/currying,
it may not make much sense to debug this the same way one would with
an imperative language such as C and its equivalent constructs.

\section{Compilation process}

\begin{figure}
  \centering
\begin{tikzpicture}[node distance=3pt,outer sep=0pt,
blueb/.style={
  draw=white,
  fill=mybluei,
  rounded corners,
  text width=2.5cm,
  %font=\scriptsize,
  font={\scriptsize\sffamily\bfseries\color{white}},
  align=center,
  text height=12pt,
  text depth=9pt},
greenb/.style={blueb,fill=mygreen},
]
\node[blueb, fill=mygreen] (prog) {OCaml source file};
\node[left=of prog] (i) {Input};
\node[blueb, below=of prog] (lex) {Lexing};
\node[blueb, below=of lex] (par) {Parsing};
\node[blueb, below=of par] (typ) {Typing};
\node[blueb, below=of typ] (lam) {Lambda};
\node[blueb, below=of lam] (clam) {Clambda};
\node[blueb, below=of clam] (cmm) {Cmm};
\node[blueb, below=of cmm] (mac) {Mach};
\node[blueb, below=of mac] (lin) {Linearize};
\node[blueb,below=of lin] (cgen) {Code generation};
\node[blueb,below=of cgen] (asm) {Assembling - Linking};
\node[blueb,fill=mypink,below=of asm] (bin) {OCaml binary};
\node[left=of bin] (o) {Output};
\end{tikzpicture}
\end{figure}

The source program goes through multiple passes/transformations:

\begin{description}
    \item[lexing - lexical analysis]
        split the program from a sequence of characters into a sequence of tokens

    \item[parsetree - syntactic analysis]

        check whether the program as a seq of tokens is gramatically valid, and if so
        construct a base in-memory representation of the program, an abstract syntax
        tree. that AST contains file and line location information.

    \item[typedtree - semantic analysis]
        annotate AST with type information
        type inference and checking

    \item[lambda]
        AST with
        pattern matching optimization,
        % to if and switch constructs,
        elimination of classes and modules,
        discards type information,
        maps the source code to runtime memory model,
        gives unique names to identifiers by append number to them
        (variable shadowing)
        loss of most of location information occurs at this point

    \item[clambda]
        closure conversion, inlining, constant propagation/folding

    \item[cmm]
        primitives conversion, constant folding

    \item[mach]
        register liveness analysis, register allocation

    \item[linearize]
        code as list/seq of pseudo-instructions, close to machine code
        with calls and jumps

    \item[code generation]

    \item[assembling and linking]
\end{description}

Among those steps, all passes up to lambda are common to both bytecode and
native compilers, the ones from clambda onwards are specific to the native compiler

% todo : make figure with all different compilation steps


\section{Additions to the compiler}

Those additions were done and tested on a x86 64-bit system using Linux, on a
closed project fork of the OCaml compiler, including memory profiling
facilities.

\subsection{Location information}

Let us define first what a debugging event is, quoting the OCaml manual:

\begin{quotation}
    Events are “interesting” locations in the source code, corresponding to the
    beginning or end of evaluation of “interesting” sub-expressions. Events are
    the unit of single-stepping (stepping goes to the next or previous event
    encountered in the program execution). Also, breakpoints can only be set at
    events. Thus, events play the role of line numbers in debuggers for
    conventional languages. \autocite{events}
\end{quotation}

Those events are here used in the bytecode with the bytecode, source-level
debugger \textit{ocamldebug}. \\

Among the debugging information to be added, line information is important,
both for stepping into the source program statement by statement,
and also for setting breakpoints by file and line number.

The idea here is to propagate the location information contained in those events
through the native code backend, by wrapping all AST/IR nodes into a record
containing the node and a field with location information from the debugging
event.

\begin{lstlisting}
type t = {
  dinfo_file: string;
  dinfo_line: int;
  dinfo_char_start: int;
  dinfo_char_end: int
}

type 'a expression = {
  exp: 'a;
  dbg: t;
}
\end{lstlisting}

This has been done for every native backend pass all the way up to the linearize
pass, whose instruction record that already contains such a field.

At the code generation step, the code emitter uses two notable debugging
assembly directives, specific to the GNU assembler as it is used in the
compilation process:

%https://sourceware.org/binutils/docs-2.26/as/Loc.html
%https://sourceware.org/binutils/docs-2.26/as/File.html

\begin{itemize}
    \item .file fileno filename : assigning a positive integer to a filename
    \item .loc fileno lineno [column] [options] : add a row to the .debug\_line
        line information matrix for the current compilation unit, map a source
        file and line number to the assembly instructions that follow

\end{itemize}

% dans le code assembleur, présence de directives .loc
%fichier - num de ligne - num de colonne
%assembleur recupere les infos et l'offset et encode tout cela dans une structure dediée dans la section .debug\_line

Then/afterwards, location information was attached to some particular nodes/constructs

integers - as empty list [] and None from the option type represented as integers
primitives - explain what a primitive is, what it is responsible for

prim operations mirroring bytecode instructions maybe?
may refer to external C function
assignments, allocation, comparisons, /string/float/integer/boolean operations,
boxed/unboxed

setfield primitive - responsible for mutable assignments

\begin{description}
\pro more info
\con less precision
\end{description}

\begin{itemize}
\tick more info
\fail less precision
\end{itemize}

Heavy modifications on the backend
% huge patch when trying to add a debugging field to every IR node
% languages des passes backend natif n'a pas prevu pour l'adjonction d'info de debug
lack of accuracy, loss of information still occuring as code is still expanded and transformed
%\item Valeurs disponibles pas toujours cohérentes
% csq du manque de precision
as a csq of lack of precision, location information directives arent put at the
most suitable assembly instruction, values might not be updated when they should
and vice versa

\subsection{Runtime location of variables}


Add 2 passes into the backend: available\_regs and available\_ranges
using forward data-flow analysis operating on Mach IR, can be traversed like
a CFG

% https://stackoverflow.com/questions/11322163/ocaml-calling-convention-is-this-an-accurate-summary

ocaml calling conventions different from C, where arguments are passed in
registers, ocaml runtime tries to reuse registers as much as it can, variables
spilled on the stack if no registers available
callees are free to destroy their callers' arguments

available\_regs
takes a function expressed in Mach code as input
return Mach code with each ins annotated with set of `registers` identifiers
whose value can be accessed (hence available) by a debugger at runtime

The data-flow equations used for a given instruction
\[
    \textit{out}_{b} = \bigcup_{s \in succ_{b}} \textit{in}_{s}
\]
\[
    \textit{in}_{b} = (\textit{out}_{b} - \textit{kill}_{b}) \cup \textit{gen}_{b}
\]

%out(b) = 0
%for s in succ(b)
  %out(b) = out(b) or in(s)
  %in(b) = (out(b) and not kill(b)) or gen(b)
available\_ranges:
operates over available\_regs output as input
calculates for each variable/ identifier used in target function the memory
addresses ranges where its content can be inspected, and for each range, the
place where the content can be accessed (in registers or on the stack)

\begin{algorithmic}[1]
    \If{some condition is true}
    \State do some processing
    \ElsIf{some other condition is true}
    \State do some different processing
    \ElsIf{some even more bizarre condition is met}
    \State do something else
    \Else
    \State do the default actions
    \EndIf
\end{algorithmic}

populate the  .debug\_info et .debug\_loc sections

unique identifier with unique stamp is generated in cases variable shadowing overwrites former value

not every value binding is captured becaused of constant folding


for each, what effect is achieved, tradeoffs
what/why/how

\subsection{DWARF emitter}

for each, what effect is achieved, tradeoffs
what/why/how

\subsection{Type information}


typed AST is serialized into the binary instead of a separate file

more practical to manipulate, comes at the cost of a bigger binary size

representation will be used later to build a symbol table for use in ocp-lldb


for each, what effect is achieved, tradeoffs
what/why/how

